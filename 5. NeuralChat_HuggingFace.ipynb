{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbd68bfb-da1f-4d99-9b5e-d752eabe3d34",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### import transformers\n",
    "\n",
    "model_name = 'Intel/neural-chat-7b-v3-1'\n",
    "#link: https://huggingface.co/Intel/neural-chat-7b-v3-1 \n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def generate_response(system_input, user_input):\n",
    "\n",
    "    # Format the input using the provided template\n",
    "    prompt = f\"### System:\\n{system_input}\\n### User:\\n{user_input}\\n### Assistant:\\n\"\n",
    "\n",
    "    # Tokenize and encode the prompt\n",
    "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\", add_special_tokens=False)\n",
    "\n",
    "    # Generate a response\n",
    "    outputs = model.generate(inputs, max_length=1000, num_return_sequences=1)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Extract only the assistant's response\n",
    "    return response.split(\"### Assistant:\\n\")[-1]\n",
    "\n",
    "\n",
    "# Example usage\n",
    "system_input = \"You are a math expert assistant. Your mission is to help users understand and solve various math problems. You should provide step-by-step solutions, explain reasonings and give the correct answer.\"\n",
    "user_input = \"calculate 1 + 2 + 30 + 7 + 9\"\n",
    "response = generate_response(system_input, user_input)\n",
    "print(response)\n",
    "\n",
    "# expected response\n",
    "\"\"\"\n",
    "To calculate the sum of 100, 520, and 60, we will follow these steps:\n",
    "\n",
    "1. Add the first two numbers: 100 + 520\n",
    "2. Add the result from step 1 to the third number: (100 + 520) + 60\n",
    "\n",
    "Step 1: Add 100 and 520\n",
    "100 + 520 = 620\n",
    "\n",
    "Step 2: Add the result from step 1 to the third number (60)\n",
    "(620) + 60 = 680\n",
    "\n",
    "So, the sum of 100, 520, and 60 is 680.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39286df6-6de0-423f-bb52-16d695f8931c",
   "metadata": {},
   "source": [
    "### import transformers\n",
    "\n",
    "model_name = 'Intel/neural-chat-7b-v3-1'\n",
    "#link: https://huggingface.co/Intel/neural-chat-7b-v3-1 \n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def generate_response(system_input, user_input):\n",
    "\n",
    "    # Format the input using the provided template\n",
    "    prompt = f\"### System:\\n{system_input}\\n### User:\\n{user_input}\\n### Assistant:\\n\"\n",
    "\n",
    "    # Tokenize and encode the prompt\n",
    "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\", add_special_tokens=False)\n",
    "\n",
    "    # Generate a response\n",
    "    outputs = model.generate(inputs, max_length=1000, num_return_sequences=1)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Extract only the assistant's response\n",
    "    return response.split(\"### Assistant:\\n\")[-1]\n",
    "\n",
    "\n",
    "# Example usage\n",
    "system_input = \"You are a math expert assistant. Your mission is to help users understand and solve various math problems. You should provide step-by-step solutions, explain reasonings and give the correct answer.\"\n",
    "user_input = \"calculate 1 + 2 + 30 + 7 + 9\"\n",
    "response = generate_response(system_input, user_input)\n",
    "print(response)\n",
    "\n",
    "# expected response\n",
    "\"\"\"\n",
    "To calculate the sum of 100, 520, and 60, we will follow these steps:\n",
    "\n",
    "1. Add the first two numbers: 100 + 520\n",
    "2. Add the result from step 1 to the third number: (100 + 520) + 60\n",
    "\n",
    "Step 1: Add 100 and 520\n",
    "100 + 520 = 620\n",
    "\n",
    "Step 2: Add the result from step 1 to the third number (60)\n",
    "(620) + 60 = 680\n",
    "\n",
    "So, the sum of 100, 520, and 60 is 680.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0f9128c-b7e1-4bd1-a5de-13050c027e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/u275fd8e4d91dab6914f7cf5e3a9bd9b/.local/lib/python3.11/site-packages (4.44.2)\n",
      "Requirement already satisfied: filelock in /home/u275fd8e4d91dab6914f7cf5e3a9bd9b/.local/lib/python3.11/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/u275fd8e4d91dab6914f7cf5e3a9bd9b/.local/lib/python3.11/site-packages (from transformers) (0.25.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/u275fd8e4d91dab6914f7cf5e3a9bd9b/.local/lib/python3.11/site-packages (from transformers) (2.1.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /srv/jupyter/python-venv/lib/python3.11/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /srv/jupyter/python-venv/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/u275fd8e4d91dab6914f7cf5e3a9bd9b/.local/lib/python3.11/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /srv/jupyter/python-venv/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/u275fd8e4d91dab6914f7cf5e3a9bd9b/.local/lib/python3.11/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/u275fd8e4d91dab6914f7cf5e3a9bd9b/.local/lib/python3.11/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/u275fd8e4d91dab6914f7cf5e3a9bd9b/.local/lib/python3.11/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/u275fd8e4d91dab6914f7cf5e3a9bd9b/.local/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /srv/jupyter/python-venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /srv/jupyter/python-venv/lib/python3.11/site-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /srv/jupyter/python-venv/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /srv/jupyter/python-venv/lib/python3.11/site-packages (from requests->transformers) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /srv/jupyter/python-venv/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/srv/jupyter/python-venv/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6421f92a7464f4894cd6b1fb5f00f49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " To calculate this expression step by step, we will add and subtract the numbers one by one.\n",
      "\n",
      "1. Start with the first number, 10.\n",
      "2. Add the next number, 2, to 10: 10 + 2 = 12.\n",
      "3. Add the next number, 3, to 12: 12 + 3 = 15.\n",
      "4. Add the next number, 4, to 15: 15 + 4 = 19.\n",
      "5. Add the next number, 5, to 19: 19 + 5 = 24.\n",
      "6. Subtract the next number, -3, from 24: 24 - 3 = 21.\n",
      "7. Add the last number, 7, to 21: 21 + 7 = 28.\n",
      "\n",
      "So, the final result is 28.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nTo calculate the sum of 100, 520, and 60, we will follow these steps:\\n\\n1. Add the first two numbers: 100 + 520\\n2. Add the result from step 1 to the third number: (100 + 520) + 60\\n\\nStep 1: Add 100 and 520\\n100 + 520 = 620\\n\\nStep 2: Add the result from step 1 to the third number (60)\\n(620) + 60 = 680\\n\\nSo, the sum of 100, 520, and 60 is 680.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install transformers\n",
    "import transformers\n",
    "model_name = 'Intel/neural-chat-7b-v3-1'\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def generate_response(system_input, user_input):\n",
    "\n",
    "    # Format the input using the provided template\n",
    "    prompt = f\"### System:\\n{system_input}\\n### User:\\n{user_input}\\n### Assistant:\\n\"\n",
    "\n",
    "    # Tokenize and encode the prompt\n",
    "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\", add_special_tokens=False)\n",
    "\n",
    "    # Generate a response\n",
    "    outputs = model.generate(inputs, max_length=1000, num_return_sequences=1)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Extract only the assistant's response\n",
    "    return response.split(\"### Assistant:\\n\")[-1]\n",
    "\n",
    "\n",
    "# Example usage\n",
    "system_input = \"Become a maths teacher, I want you to explain me step by step the calculations for user input .\"\n",
    "user_input = \"10 + 2 + 3 + 4 + 5 -3 + 7\"\n",
    "response = generate_response(system_input, user_input)\n",
    "print(response)\n",
    "\n",
    "# expected response\n",
    "\"\"\"\n",
    "To calculate the sum of 100, 520, and 60, we will follow these steps:\n",
    "\n",
    "1. Add the first two numbers: 100 + 520\n",
    "2. Add the result from step 1 to the third number: (100 + 520) + 60\n",
    "\n",
    "Step 1: Add 100 and 520\n",
    "100 + 520 = 620\n",
    "\n",
    "Step 2: Add the result from step 1 to the third number (60)\n",
    "(620) + 60 = 680\n",
    "\n",
    "So, the sum of 100, 520, and 60 is 680.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9135942-ae14-4c89-92c5-291d872dcb16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e8954c-5b15-4727-9a45-9b0d1b775315",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3dde9b-e61e-4048-a50e-2cfdc62b1c89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b7b9d7-0195-4d14-b1f2-7c3936b70cf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
